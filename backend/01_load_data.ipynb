{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfzOMyCyjfKL"
   },
   "source": [
    "## **Loading Data to BigQuery**\n",
    "\n",
    "* In this notebook below operatins are done :\n",
    "\n",
    "1. setting up environment - creating gcs buckets, bigquery datasets.\n",
    "2. Loading data to BQ Bronze layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fs11SlAmizlg"
   },
   "source": [
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/smvinodkumar910/market-mirror/blob/main/backend/01_load_data.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Fsmvinodkumar910%2Fmarket-mirror%2Frefs%2Fheads%2Fmain%2Fbackend%2F01_load_data.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/smvinodkumar910/market-mirror/refs/heads/main/backend/01_load_data.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/smvinodkumar910/market-mirror/blob/main/backend/01_load_data.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/475654/github-color.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNsd-fI3mYHM"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the following cell to authenticate your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1755451447798,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "QBdSXkfcmc9c",
    "outputId": "1bc63eb4-c6d6-4c57-c196-0cbaf1d0e8ae"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Support for third party widgets\n",
    "    from google.colab import auth, output\n",
    "\n",
    "    auth.authenticate_user()\n",
    "    output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckhjHdl0VxvZ"
   },
   "source": [
    "### Setting-up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Please change the variables `PROJECT_ID`, `BUCKET_NAME`, `LOCATION` details to your own project as required.\n",
    "\n",
    "* In this project we are following Medallion architecture to load and proeceess data in BQ datawarehouse.\n",
    "\n",
    "* Hence 3 BQ datasets defined below, namely `BQ_BRONZE_DATASET`, `BQ_SILVER_DATASET` and `BQ_GOLD_DATASET`. \n",
    "\n",
    "* You can leave it as its to load and process data in respective datasets, or you can change if you preferent different name for the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1755451448518,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "L02uxb6fwRz5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"market-mirror-dev\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
    "BUCKET_NAME = \"marke-mirror-dev-data\"  # @param {type: \"string\", placeholder: \"[your-bucket-name]\", isTemplate: true}\n",
    "LOCATION = \"us-central1\"  # @param {type: \"string\", placeholder: \"[your-region]\", isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "if not LOCATION or LOCATION == \"[your-region]\":\n",
    "    LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1755451448518,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "Ae8j4N0ulv0Z"
   },
   "outputs": [],
   "source": [
    "BQ_BRONZE_DATASET = \"APP_MARKET_BRONZE\" # @param {type: \"string\", placeholder: \"[bronze-dataset]\", isTemplate: true}\n",
    "BQ_SILVER_DATASET = \"APP_MARKET_SILVER\" # @param {type: \"string\", placeholder: \"[silver-dataset]\", isTemplate: true}\n",
    "BQ_GOLD_DATASET = \"APP_MARKET_GOLD\" # @param {type: \"string\", placeholder: \"[gold-dataset]\", isTemplate: true}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUsRjtqymYR1"
   },
   "source": [
    "#### Prepare GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section we are creating GCS bucket required to Upload RAW files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1755451448518,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "hP-bc_WVmW1P"
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud.exceptions import NotFound\n",
    "\n",
    "gcs_client = storage.Client(\n",
    "    project=PROJECT_ID\n",
    ")\n",
    "\n",
    "try:\n",
    "  databucket = gcs_client.get_bucket(BUCKET_NAME)\n",
    "  bucket_exists = True\n",
    "except NotFound:\n",
    "  databucket = gcs_client.create_bucket(BUCKET_NAME, project=PROJECT_ID)\n",
    "  bucket_exists = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGJaRb78XdLf"
   },
   "source": [
    "#### Prepare BigQuery Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section we are creating required datasets in BQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1536,
     "status": "ok",
     "timestamp": 1755451450050,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "6umLktvxCItU",
    "outputId": "31b14936-8f9f-4f0c-a076-9420d09c9831"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "bq_client.create_dataset(BQ_BRONZE_DATASET,exists_ok=True)\n",
    "bq_client.create_dataset(BQ_SILVER_DATASET,exists_ok=True)\n",
    "bq_client.create_dataset(BQ_GOLD_DATASET,exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXzmyv-mV-zw"
   },
   "source": [
    "### Data Load Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRcHOFmDkxEr"
   },
   "source": [
    "#### Data Definitions\n",
    "\n",
    "We are going to use 5 Kaggle Datasets for this project.\n",
    "\n",
    "**Reviews Dataset :**\n",
    "* This dataset will be used to explore the sentiment of user reviews on Google Play Store Apps. \n",
    "1. https://www.kaggle.com/datasets/lava18/google-play-store-apps\n",
    "2. https://www.kaggle.com/datasets/marianna13/google-play-reviews\n",
    "\n",
    "**Product Details Dataset:**\n",
    "* This dataset will be used to compare the products in Goole Play store with competitive products in other platforms like Apple and Windows.\n",
    "1. https://www.kaggle.com/datasets/maryamsayagh1/google-play-store-apps\n",
    "2. https://www.kaggle.com/datasets/ramamet4/app-store-apple-data-set-10k-apps\n",
    "3. https://www.kaggle.com/datasets/quadeer15sh/windows-store-top-apps-games\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXvIfXeSW6Y5"
   },
   "source": [
    "#### Download Data from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section, we are downloading data from Kaggle datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 727,
     "status": "ok",
     "timestamp": 1755451450774,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "rCWjjAKmp1ph"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os, glob\n",
    "\n",
    "product_datasets_list = [\n",
    "'https://www.kaggle.com/datasets/maryamsayagh1/google-play-store-apps',\n",
    "'https://www.kaggle.com/datasets/ramamet4/app-store-apple-data-set-10k-apps',\n",
    "'https://www.kaggle.com/datasets/quadeer15sh/windows-store-top-apps-games']\n",
    "\n",
    "\n",
    "reviews_datasets_list = ['https://www.kaggle.com/datasets/lava18/google-play-store-apps',\n",
    "'https://www.kaggle.com/datasets/marianna13/google-play-reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below step downloads all review datasets from Kaggle to local path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3569,
     "status": "ok",
     "timestamp": 1755451454341,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "hdUAaI73qGo2"
   },
   "outputs": [],
   "source": [
    "review_local_paths = []\n",
    "for dataset in reviews_datasets_list:\n",
    "  dataset_path = dataset.replace('https://www.kaggle.com/datasets/','')\n",
    "  dataset_name = dataset.split('/')[-1]\n",
    "  path = kagglehub.dataset_download(dataset_path)\n",
    "  files_path = glob.glob(pathname=os.path.join(path,'*'))\n",
    "  review_local_paths.append({'dataset_name': dataset_name, 'path':files_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below step downloads all product datasets from Kaggle to local path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6117,
     "status": "ok",
     "timestamp": 1755451460453,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "vnYbtLldMsvQ"
   },
   "outputs": [],
   "source": [
    "product_local_paths = []\n",
    "for dataset in product_datasets_list:\n",
    "  dataset_path = dataset.replace('https://www.kaggle.com/datasets/','')\n",
    "  dataset_name = dataset.split('/')[-1]\n",
    "  path = kagglehub.dataset_download(dataset_path)\n",
    "  files_path = glob.glob(pathname=os.path.join(path,'*'))\n",
    "  product_local_paths.append({'dataset_name': dataset_name, 'path':files_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVygYUjmXMND"
   },
   "source": [
    "#### Upload Data to GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below step uploads the files stored in local filesystem to GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 747,
     "status": "ok",
     "timestamp": 1755451461196,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "KlVuhiJmNKQd",
    "outputId": "4748afb7-5f6c-4fad-f3a1-20e2a2def3e9"
   },
   "outputs": [],
   "source": [
    "#Uploading reivew datasets\n",
    "review_gcs_files = []\n",
    "if bucket_exists:\n",
    "  for file in review_local_paths:\n",
    "    dataset_name = file.get('dataset_name')\n",
    "    paths = file.get('path')\n",
    "    for path in paths:\n",
    "      file_name = path.split('/')[-1]\n",
    "      destination_blob_name = os.path.join('review_dataset',dataset_name,file_name)\n",
    "      destination_blob = databucket.blob(destination_blob_name)\n",
    "      destination_blob.upload_from_filename(path)\n",
    "      review_gcs_files.append(f\"gs://{BUCKET_NAME}/{destination_blob_name}\")\n",
    "      print(\n",
    "          f\"File {path} uploaded to gs://{BUCKET_NAME}/{destination_blob_name}.\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2340,
     "status": "ok",
     "timestamp": 1755451463535,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "6fXhJhwtxt0m",
    "outputId": "844bb806-ace4-4478-ce19-11b791e08bcd"
   },
   "outputs": [],
   "source": [
    "#Uploading product datasets\n",
    "product_gcs_files = []\n",
    "if bucket_exists:\n",
    "  for file in product_local_paths:\n",
    "    dataset_name = file.get('dataset_name')\n",
    "    paths = file.get('path')\n",
    "    for path in paths:\n",
    "      file_name = path.split('/')[-1]\n",
    "      destination_blob_name = os.path.join('product_dataset',dataset_name,file_name)\n",
    "      destination_blob = databucket.blob(destination_blob_name)\n",
    "      destination_blob.upload_from_filename(path)\n",
    "      product_gcs_files.append(f\"gs://{BUCKET_NAME}/{destination_blob_name}\")\n",
    "      print(\n",
    "          f\"File {path} uploaded to gs://{BUCKET_NAME}/{destination_blob_name}.\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmhD9RXCXnED"
   },
   "source": [
    "#### Write Data to BigQuery Bronze Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this step we are loading data from GCS Bucket to BQ using Bigframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1755451464290,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "CdJtbuXjRbxy"
   },
   "outputs": [],
   "source": [
    "import bigframes.pandas as bpd\n",
    "\n",
    "bpd.options.bigquery.project = PROJECT_ID\n",
    "bpd.options.bigquery.dataset = BQ_BRONZE_DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtering reivew files with .csv files only and loading in BQ Bronze layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1755451464290,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "cymvlmMISFbP"
   },
   "outputs": [],
   "source": [
    "review_gcs_files_filtered = [{'file_name':file.split('/')[-1].split('.')[0], 'gcs_path': file} for file in review_gcs_files if (file.endswith('.csv')  and 'review' in file.split('/')[-1].split('.')[0] ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 23090,
     "status": "ok",
     "timestamp": 1755451487374,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "vygSxhJMFyyg",
    "outputId": "ccc1fd5e-efa9-4424-9421-a9490a5c781c"
   },
   "outputs": [],
   "source": [
    "#start processing files\n",
    "for file_dtl in review_gcs_files_filtered:\n",
    "  df = bpd.read_csv(file_dtl.get('gcs_path'))\n",
    "  df.to_gbq(f'{BQ_BRONZE_DATASET}.{file_dtl.get(\"file_name\")}', if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtering product data files with .csv extension and loading into BQ Bronze layer with dataproc serverless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ct5KwMi8KDTi"
   },
   "outputs": [],
   "source": [
    "product_gcs_files_filtered = [{'file_name':file.split('/')[-1].split('.')[0], 'gcs_path': file} for file in product_gcs_files if file.endswith('.csv') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "executionInfo": {
     "elapsed": 113748,
     "status": "ok",
     "timestamp": 1755436539195,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "B4-r8OEaKgJl",
    "outputId": "dfdec412-6014-438e-c897-37408f5d68e3"
   },
   "outputs": [],
   "source": [
    "from google.cloud.dataproc_spark_connect import DataprocSparkSession\n",
    "from google.cloud.dataproc_v1 import Session\n",
    "\n",
    "\n",
    "# This will create a default Spark session\n",
    "spark = DataprocSparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 71071,
     "status": "ok",
     "timestamp": 1755436675875,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "jBjMXsfUD6O6",
    "outputId": "1186d5a0-bf90-489a-a0fe-5230d489d513"
   },
   "outputs": [],
   "source": [
    "for file in product_gcs_files_filtered:\n",
    "  table_name = file.get('file_name')\n",
    "  print(table_name)\n",
    "  df = spark.read\\\n",
    "  .option(\"multiLine\", \"true\")\\\n",
    "  .option(\"quote\", \"\\\"\")\\\n",
    "  .option(\"escape\", '\"')\\\n",
    "  .csv(file.get('gcs_path'),\n",
    "        inferSchema=True,\n",
    "        header=True)\n",
    "  col_rename = [{f\"{column}\":f\"{column.replace(' ','_').replace('.','_')}\"} for column in df.columns]\n",
    "  all_col_rename = dict()\n",
    "  for a in col_rename:\n",
    "    all_col_rename.update(a)\n",
    "  df = df.withColumnsRenamed(all_col_rename)\n",
    "  df.write.mode(\"overwrite\").format('bigquery').save(f'{PROJECT_ID}.{BQ_BRONZE_DATASET}.{table_name}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "cell_execution_strategy": "setup",
   "name": "backend/01_load_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
